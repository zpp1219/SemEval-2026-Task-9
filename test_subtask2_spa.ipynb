{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1364f5f5-bc34-4ee8-b0e3-6f9a63d31236",
   "metadata": {},
   "source": [
    "# dev_phase测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a51b29-b508-464e-a22a-4f7ba68e3481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  9 20:27:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8             29W /  350W |   23727MiB /  24576MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3920    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            4748    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            6448    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10108    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10168    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10852    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           11176    C+G   ...8wekyb3d8bbwe\\WebViewHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11696    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13932    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13940    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           14740    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15616    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15900    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19324    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           19412    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           20576    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           21048    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A           23320    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           25524    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           33952      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           36852    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           39736    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           41648    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           44176    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           45580    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           46796    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47280    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47356    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           50772    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           51868    C+G   ...0.2.1\\jbr\\bin\\jcef_helper.exe      N/A      |\n",
      "|    0   N/A  N/A           52948    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           53208      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           54424    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           58344    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59364    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59536      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           63456    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           64552    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           64820    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           66724      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           70912    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           71576      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           72048    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           72312    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           73192      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           79908    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc308baa-8cf7-46b6-ba20-8307c320a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "WEIGHTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c8015c-0887-46ac-9e0f-3ceabc63c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 165 examples [00:00, 14996.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(load_dataset(\"dev_phase/subtask2/dev/spa\", split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8da96b4-e1d9-4fa6-a8ef-847ccde8cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split size: 165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>\"puta weon, los progres arruinaron el indio pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>#mexico | el gobierno informo que esta dialoga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>a abortar el mojon que traen atorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>a comerrrrr\\n(la salsa es curry indio)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>aborto libre y retroactivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065   \n",
       "\n",
       "                                                text  \n",
       "0  \"puta weon, los progres arruinaron el indio pi...  \n",
       "1  #mexico | el gobierno informo que esta dialoga...  \n",
       "2               a abortar el mojon que traen atorado  \n",
       "3             a comerrrrr\\n(la salsa es curry indio)  \n",
       "4                         aborto libre y retroactivo  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"political\", \"racial/ethnic\", \"religious\", \"gender/sexual\", \"other\"]\n",
    "def get_text_and_label(df):  \n",
    "  return df.rename(columns={\"text\": \"text\"})[[\"id\", \"text\"]]\n",
    "test = get_text_and_label(test)\n",
    "print(\"Test split size:\", len(test.index))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5de4b28-8ee2-4401-a2e8-d8066d5e91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = \"lr-2e-05-optimizer-AdamW-epochs-10-RMSEduringTraining\"\n",
    "EXP = \"09-11-2025-00-03\"\n",
    "# TRANSFORMERS = \"top_transformers\"  \n",
    "TRANSFORMERS = \"09-11-2025-00-03\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54cdabce-fa36-4cb2-ae97-4218c2e39236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: ./outputs/09-11-2025-00-03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./outputs/\"\n",
    "EXP_PATH = os.path.join(PATH, EXP)\n",
    "TRANSFORMERS_PATH = os.path.join(PATH, TRANSFORMERS)\n",
    "print(\"Current working dir:\", EXP_PATH)\n",
    "OUTPUT = os.path.join(EXP_PATH, \"test\")\n",
    "# 第一次使用时创建文件夹\n",
    "# os.mkdir(EXP_PATH)\n",
    "# os.mkdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c485887e-a838-46d0-8dc5-80ea0c47444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {    \n",
    "\"mbert-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-cased\"    \n",
    "},    \n",
    "\"mbert-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-uncased\"    \n",
    "},    \n",
    "\"roberta\": {        \n",
    "\"model_type\": \"roberta\",        \n",
    "\"model_name\": \"models--FacebookAI--roberta-base\"    \n",
    "},    \n",
    "\"beto-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-cased\"    \n",
    "},    \n",
    "\"beto-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-uncased\"    \n",
    "},    \n",
    "\"distilbert-multi\": {        \n",
    "\"model_type\": \"distilbert\",        \n",
    "\"model_name\": \"models--distilbert--distilbert-base-multilingual-cased\"    \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e6dff70-fca9-4021-8c8b-b97ab17c99bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mbert-cased\n",
      "model: mbert-uncased\n",
      "model: roberta\n",
      "model: beto-cased\n",
      "model: beto-uncased\n",
      "model: distilbert-multi\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "for model, fields in models.items():    \n",
    "  print(\"model:\",model)\n",
    "  models[model] = MultiLabelClassificationModel(fields[\"model_type\"], os.path.join(TRANSFORMERS_PATH, model), use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ff1feef-2a7e-4e05-a639-b6bc0a76ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BEST ENSEMBLE -----\n",
      "name: ensemble18\n",
      "models: ['beto-cased', 'beto-uncased']\n",
      "metrics: {'accuracy': 0.97035, 'macro_f1': 0.98024, 'macro_precision': 0.99442, 'macro_recall': 0.96671, 'weighted_f1': 0.98177}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_ensemble = {}\n",
    "with open(os.path.join(EXP_PATH, \"best-ensemble.json\")) as json_file:\n",
    "    best_ensemble = json.load(json_file)\n",
    "print(\"----- BEST ENSEMBLE -----\")\n",
    "for field in [\"name\", \"models\", \"metrics\"]:\n",
    "  print(f\"{field}:\", best_ensemble.get(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b818f009-115d-40b8-bd22-eadbdecae834",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = {}\n",
    "for model in best_ensemble.get(\"models\"):  \n",
    "  with open(os.path.join(os.path.join(EXP_PATH, model), \"model-evaluation.json\")) as json_file:\n",
    "      model_evaluation[model] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0fd6fc6-371e-4ba6-883f-36dad4a5b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def vote(predictions, weighted=False, weights=None):\n",
    "  votes = list()  \n",
    "  for i in range(len(labels)):    \n",
    "    curr_label_preds = [preds[i] for preds in predictions]    \n",
    "    voting = sum(curr_label_preds * weights) if weighted else sum(curr_label_preds)/len(curr_label_preds)\n",
    "    votes.append(0 if voting < 0.5 else 1)  \n",
    "  return votes\n",
    "test_predictions = list()\n",
    "def predict_ensemble(ensemble_name, dataset_name, dataset, weighted=False):  \n",
    " for i in range(len(dataset.index)):\n",
    "    predictions = list()\n",
    "    ensemble_models = best_ensemble.get(\"models\")    \n",
    "    for model_name in ensemble_models:\n",
    "      curr_model_outputs = model_evaluation[model_name].get(f\"{dataset_name}_model_outputs\")\n",
    "      predictions.append(curr_model_outputs[i])\n",
    "    weights = list()    \n",
    "    if weighted:      \n",
    "      f1_scores_list = [model_evaluation[model_name][\"metrics\"].get(\"weighted_f1\")                        \n",
    "                        for model_name in best_ensemble.get(\"models\")]\n",
    "      weights = normalize([f1_scores_list], norm=\"l1\")[0]\n",
    "    ensemble_pred = vote(predictions, weighted, weights)\n",
    "    test_predictions.append(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5aeddf3-55af-45bd-800e-d4fe46a7c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.42s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:12<00:00,  1.68it/s]\n",
      "1it [00:02,  2.35s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:12<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions: [[0, 1, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in best_ensemble.get(\"models\"):\n",
    "  model_predictions, model_raw_outputs = models.get(model_name).predict(test[\"text\"].tolist())\n",
    "  model_evaluation[model_name][\"test_model_outputs\"] = model_raw_outputs\n",
    "  model_evaluation[model_name][\"test_predictions\"] = model_predictions\n",
    "predict_ensemble(best_ensemble.get(\"name\"), \"test\", test, weighted=WEIGHTED)\n",
    "n = 5\n",
    "print(f\"First {n} predictions:\", test_predictions[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d85898c4-49a7-4a19-9fe0-62b6db342e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>political</th>\n",
       "      <th>racial/ethnic</th>\n",
       "      <th>religious</th>\n",
       "      <th>gender/sexual</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa_ae37ea460c69447a6e03c3dedf946126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spa_dda5476589aee9d32a5ee7432805999c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa_1a721702be59d86b876810539ad9cf66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spa_bec4c459366c1a56819a55c01dc1a77d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  political  racial/ethnic  religious  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888          0              1          0   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc          0              0          0   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe          0              0          0   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928          0              0          0   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065          0              0          0   \n",
       "5  spa_ae37ea460c69447a6e03c3dedf946126          0              0          0   \n",
       "6  spa_dda5476589aee9d32a5ee7432805999c          1              0          0   \n",
       "7  spa_1a721702be59d86b876810539ad9cf66          0              0          0   \n",
       "8  spa_bec4c459366c1a56819a55c01dc1a77d          0              0          0   \n",
       "9  spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9          1              0          0   \n",
       "\n",
       "   gender/sexual  other  \n",
       "0              0      0  \n",
       "1              0      0  \n",
       "2              0      1  \n",
       "3              0      0  \n",
       "4              0      0  \n",
       "5              0      0  \n",
       "6              0      1  \n",
       "7              0      0  \n",
       "8              0      0  \n",
       "9              0      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = test[[\"id\"]].rename(columns={\"id\": \"id\"})\n",
    "for i in range(len(labels)):\n",
    "  test_output[labels[i]] = [pred[i] for pred in test_predictions]\n",
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14859ef4-50f1-4604-94c8-a5893d30b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(os.path.join(OUTPUT, \"results_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b2113-b8ce-48bb-b449-4bf262a793f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d87f792f-bb30-4a45-b8ca-93e67f01181e",
   "metadata": {},
   "source": [
    "# dev_phase2 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "202f2109-bf0d-450d-bf25-d5dcf6cb6504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  9 20:38:05 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8             30W /  350W |   23738MiB /  24576MiB |     11%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3920    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            4748    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            6448    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10108    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10168    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10852    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           11176    C+G   ...8wekyb3d8bbwe\\WebViewHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11696    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13932    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13940    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           14740    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15616    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15900    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19324    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           19412    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           20576    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           21048    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A           23320    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           25524    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           33952      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           36852    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           39736    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           41648    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           44176    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           45580    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           46796    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47280    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47356    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           50772    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           51868    C+G   ...0.2.1\\jbr\\bin\\jcef_helper.exe      N/A      |\n",
      "|    0   N/A  N/A           52948    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           53208      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           54424    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           58344    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59364    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59536      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           63456    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           64552    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           64820    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           66724      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           70912    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           71576      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           72048    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           72312    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           73192      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           79908    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ee12463-e608-49c6-b90d-9094ac69b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "WEIGHTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cc569e5-dfca-44f0-b46b-bc1fe5decff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(load_dataset(\"dev_phase2/subtask2/dev/spa\", split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccd8d3b1-9f37-47ae-97b0-78719ddfabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split size: 165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>\"puta weon, los progres arruinaron el indio pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>#mexico | el gobierno informo que esta dialoga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>a abortar el mojon que traen atorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>a comerrrrr\\n(la salsa es curry indio)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>aborto libre y retroactivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065   \n",
       "\n",
       "                                                text  \n",
       "0  \"puta weon, los progres arruinaron el indio pi...  \n",
       "1  #mexico | el gobierno informo que esta dialoga...  \n",
       "2               a abortar el mojon que traen atorado  \n",
       "3             a comerrrrr\\n(la salsa es curry indio)  \n",
       "4                         aborto libre y retroactivo  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"political\", \"racial/ethnic\", \"religious\", \"gender/sexual\", \"other\"]\n",
    "def get_text_and_label(df):  \n",
    "  return df.rename(columns={\"text\": \"text\"})[[\"id\", \"text\"]]\n",
    "test = get_text_and_label(test)\n",
    "print(\"Test split size:\", len(test.index))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e65d04d-8f2d-4ca5-8e0e-0f71a49ef858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = \"lr-2e-05-optimizer-AdamW-epochs-10-RMSEduringTraining\"\n",
    "EXP = \"09-11-2025-00-03\"\n",
    "# TRANSFORMERS = \"top_transformers\"  \n",
    "TRANSFORMERS = \"09-11-2025-00-03\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c9c2f7a-58fd-4a12-a0cb-5528983e175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: ./outputs/09-11-2025-00-03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./outputs/\"\n",
    "EXP_PATH = os.path.join(PATH, EXP)\n",
    "TRANSFORMERS_PATH = os.path.join(PATH, TRANSFORMERS)\n",
    "print(\"Current working dir:\", EXP_PATH)\n",
    "OUTPUT = os.path.join(EXP_PATH, \"test\")\n",
    "# 第一次使用时创建文件夹\n",
    "# os.mkdir(EXP_PATH)\n",
    "# os.mkdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "786f0eba-0dc8-424e-b0df-fc51de711796",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {    \n",
    "\"mbert-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-cased\"    \n",
    "},    \n",
    "\"mbert-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-uncased\"    \n",
    "},    \n",
    "\"roberta\": {        \n",
    "\"model_type\": \"roberta\",        \n",
    "\"model_name\": \"models--FacebookAI--roberta-base\"    \n",
    "},    \n",
    "\"beto-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-cased\"    \n",
    "},    \n",
    "\"beto-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-uncased\"    \n",
    "},    \n",
    "\"distilbert-multi\": {        \n",
    "\"model_type\": \"distilbert\",        \n",
    "\"model_name\": \"models--distilbert--distilbert-base-multilingual-cased\"    \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e774c56c-702f-4808-8417-ae0e4618039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mbert-cased\n",
      "model: mbert-uncased\n",
      "model: roberta\n",
      "model: beto-cased\n",
      "model: beto-uncased\n",
      "model: distilbert-multi\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "for model, fields in models.items():    \n",
    "  print(\"model:\",model)\n",
    "  models[model] = MultiLabelClassificationModel(fields[\"model_type\"], os.path.join(TRANSFORMERS_PATH, model), use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b13d02d3-f265-43df-91d2-0cf1f7c0f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BEST ENSEMBLE -----\n",
      "name: ensemble18\n",
      "models: ['beto-cased', 'beto-uncased']\n",
      "metrics: {'accuracy': 0.97035, 'macro_f1': 0.98024, 'macro_precision': 0.99442, 'macro_recall': 0.96671, 'weighted_f1': 0.98177}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_ensemble = {}\n",
    "with open(os.path.join(EXP_PATH, \"best-ensemble.json\")) as json_file:\n",
    "    best_ensemble = json.load(json_file)\n",
    "print(\"----- BEST ENSEMBLE -----\")\n",
    "for field in [\"name\", \"models\", \"metrics\"]:\n",
    "  print(f\"{field}:\", best_ensemble.get(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0513c17b-c570-4421-b3fb-ed8ccd3b861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = {}\n",
    "for model in best_ensemble.get(\"models\"):  \n",
    "  with open(os.path.join(os.path.join(EXP_PATH, model), \"model-evaluation.json\")) as json_file:\n",
    "      model_evaluation[model] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68f30b9a-cf32-4d30-9804-36213b7666e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def vote(predictions, weighted=False, weights=None):\n",
    "  votes = list()  \n",
    "  for i in range(len(labels)):    \n",
    "    curr_label_preds = [preds[i] for preds in predictions]    \n",
    "    voting = sum(curr_label_preds * weights) if weighted else sum(curr_label_preds)/len(curr_label_preds)\n",
    "    votes.append(0 if voting < 0.5 else 1)  \n",
    "  return votes\n",
    "test_predictions = list()\n",
    "def predict_ensemble(ensemble_name, dataset_name, dataset, weighted=False):  \n",
    " for i in range(len(dataset.index)):\n",
    "    predictions = list()\n",
    "    ensemble_models = best_ensemble.get(\"models\")    \n",
    "    for model_name in ensemble_models:\n",
    "      curr_model_outputs = model_evaluation[model_name].get(f\"{dataset_name}_model_outputs\")\n",
    "      predictions.append(curr_model_outputs[i])\n",
    "    weights = list()    \n",
    "    if weighted:      \n",
    "      f1_scores_list = [model_evaluation[model_name][\"metrics\"].get(\"weighted_f1\")                        \n",
    "                        for model_name in best_ensemble.get(\"models\")]\n",
    "      weights = normalize([f1_scores_list], norm=\"l1\")[0]\n",
    "    ensemble_pred = vote(predictions, weighted, weights)\n",
    "    test_predictions.append(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ac83f95-72b1-468a-b5ef-08a0cd1cfd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:13<00:00,  1.60it/s]\n",
      "1it [00:02,  2.46s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:13<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions: [[0, 1, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in best_ensemble.get(\"models\"):\n",
    "  model_predictions, model_raw_outputs = models.get(model_name).predict(test[\"text\"].tolist())\n",
    "  model_evaluation[model_name][\"test_model_outputs\"] = model_raw_outputs\n",
    "  model_evaluation[model_name][\"test_predictions\"] = model_predictions\n",
    "predict_ensemble(best_ensemble.get(\"name\"), \"test\", test, weighted=WEIGHTED)\n",
    "n = 5\n",
    "print(f\"First {n} predictions:\", test_predictions[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "262b7b42-3fb7-442c-ba70-f283d2d44a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>political</th>\n",
       "      <th>racial/ethnic</th>\n",
       "      <th>religious</th>\n",
       "      <th>gender/sexual</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa_ae37ea460c69447a6e03c3dedf946126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spa_dda5476589aee9d32a5ee7432805999c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa_1a721702be59d86b876810539ad9cf66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spa_bec4c459366c1a56819a55c01dc1a77d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  political  racial/ethnic  religious  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888          0              1          0   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc          0              0          0   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe          0              0          0   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928          0              0          0   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065          0              0          0   \n",
       "5  spa_ae37ea460c69447a6e03c3dedf946126          0              0          0   \n",
       "6  spa_dda5476589aee9d32a5ee7432805999c          1              0          0   \n",
       "7  spa_1a721702be59d86b876810539ad9cf66          0              0          0   \n",
       "8  spa_bec4c459366c1a56819a55c01dc1a77d          0              0          0   \n",
       "9  spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9          1              0          0   \n",
       "\n",
       "   gender/sexual  other  \n",
       "0              0      0  \n",
       "1              0      0  \n",
       "2              0      1  \n",
       "3              0      0  \n",
       "4              0      0  \n",
       "5              0      0  \n",
       "6              0      1  \n",
       "7              0      0  \n",
       "8              0      0  \n",
       "9              0      0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = test[[\"id\"]].rename(columns={\"id\": \"id\"})\n",
    "for i in range(len(labels)):\n",
    "  test_output[labels[i]] = [pred[i] for pred in test_predictions]\n",
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b9f0484-0be3-41ab-9b33-7439d0ce9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(os.path.join(OUTPUT, \"results_test2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a74f8e-5bd9-4e91-92f7-03a19976ba89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538ef1c5-633d-4616-a401-5b873f547a63",
   "metadata": {},
   "source": [
    "# test_phase 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cd3a39-7b2d-4131-a3b3-bd3411e3d538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  1 12:26:29 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.40                 Driver Version: 576.40         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   47C    P8             29W /  390W |   23724MiB /  24576MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2288    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            3044    C+G   ....0.3719.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            3124    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            4548    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7088    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7376    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7760      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A            7972    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A            8308    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            8784    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8996    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           11708    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11716    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12776    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13752    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           16792    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16932    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18292    C+G   ....0.3719.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19284      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           20816    C+G   ...0.2.1\\jbr\\bin\\jcef_helper.exe      N/A      |\n",
      "|    0   N/A  N/A           24332    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           24492    C+G   ....0.3719.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24744      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           25024    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           25504    C+G   ...8wekyb3d8bbwe\\M365Copilot.exe      N/A      |\n",
      "|    0   N/A  N/A           26696      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622b3d3b-3fb6-4e64-b003-0b0c209416d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "WEIGHTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f809d88c-35db-48ca-8fa5-a84695ad6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\SemEval2025_Task11\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(load_dataset(\"test_phase/subtask2/test/spa\", split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a78d72d-35d0-4658-8254-e4c0e4890d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split size: 1488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_1927fe24b83567b6383c90c35473cc32</td>\n",
       "      <td>\"penas severas para el aborto porque yo estuve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_73b413c77432d415f2b63397ccbcda28</td>\n",
       "      <td>\"si eres pobre debes abortar\" eso lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_5f0a632b6b0b4544b5fed6c84bd1b997</td>\n",
       "      <td>#brasil exige a #eeuu \"respeto\" para repatriad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b23cc0db2a4e552a93fbbfe4e4d2f45f</td>\n",
       "      <td>#honduras | el canciller anuncio la llegada de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_90240d10f79a2761cbea0b76e1553a6f</td>\n",
       "      <td>#internacionales | el presidente de colombia, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  spa_1927fe24b83567b6383c90c35473cc32   \n",
       "1  spa_73b413c77432d415f2b63397ccbcda28   \n",
       "2  spa_5f0a632b6b0b4544b5fed6c84bd1b997   \n",
       "3  spa_b23cc0db2a4e552a93fbbfe4e4d2f45f   \n",
       "4  spa_90240d10f79a2761cbea0b76e1553a6f   \n",
       "\n",
       "                                                text  \n",
       "0  \"penas severas para el aborto porque yo estuve...  \n",
       "1              \"si eres pobre debes abortar\" eso lei  \n",
       "2  #brasil exige a #eeuu \"respeto\" para repatriad...  \n",
       "3  #honduras | el canciller anuncio la llegada de...  \n",
       "4  #internacionales | el presidente de colombia, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"political\", \"racial/ethnic\", \"religious\", \"gender/sexual\", \"other\"]\n",
    "def get_text_and_label(df):  \n",
    "  return df.rename(columns={\"text\": \"text\"})[[\"id\", \"text\"]]\n",
    "test = get_text_and_label(test)\n",
    "print(\"Test split size:\", len(test.index))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d327081f-4b4c-4028-a3f2-7a324b19b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = \"lr-2e-05-optimizer-AdamW-epochs-10-RMSEduringTraining\"\n",
    "EXP = \"09-11-2025-00-03\"\n",
    "# TRANSFORMERS = \"top_transformers\"  \n",
    "TRANSFORMERS = \"09-11-2025-00-03\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86247f46-5c1d-4d41-9bef-156fe421a4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: ./outputs/09-11-2025-00-03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./outputs/\"\n",
    "EXP_PATH = os.path.join(PATH, EXP)\n",
    "TRANSFORMERS_PATH = os.path.join(PATH, TRANSFORMERS)\n",
    "print(\"Current working dir:\", EXP_PATH)\n",
    "OUTPUT = os.path.join(EXP_PATH, \"test\")\n",
    "# 第一次使用时创建文件夹\n",
    "# os.mkdir(EXP_PATH)\n",
    "# os.mkdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca64cb9-3aec-4538-a237-e69e0681a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {    \n",
    "\"mbert-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-cased\"    \n",
    "},    \n",
    "\"mbert-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-uncased\"    \n",
    "},    \n",
    "\"roberta\": {        \n",
    "\"model_type\": \"roberta\",        \n",
    "\"model_name\": \"models--FacebookAI--roberta-base\"    \n",
    "},    \n",
    "\"beto-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-cased\"    \n",
    "},    \n",
    "\"beto-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-uncased\"    \n",
    "},    \n",
    "\"distilbert-multi\": {        \n",
    "\"model_type\": \"distilbert\",        \n",
    "\"model_name\": \"models--distilbert--distilbert-base-multilingual-cased\"    \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4b1e23-6872-40bf-ac9c-69650231c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mbert-cased\n",
      "model: mbert-uncased\n",
      "model: roberta\n",
      "model: beto-cased\n",
      "model: beto-uncased\n",
      "model: distilbert-multi\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "for model, fields in models.items():    \n",
    "  print(\"model:\",model)\n",
    "  models[model] = MultiLabelClassificationModel(fields[\"model_type\"], os.path.join(TRANSFORMERS_PATH, model), use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900cae9d-1c06-44c4-9546-6cd00c874e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BEST ENSEMBLE -----\n",
      "name: ensemble18\n",
      "models: ['beto-cased', 'beto-uncased']\n",
      "metrics: {'accuracy': 0.97035, 'macro_f1': 0.98024, 'macro_precision': 0.99442, 'macro_recall': 0.96671, 'weighted_f1': 0.98177}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_ensemble = {}\n",
    "with open(os.path.join(EXP_PATH, \"best-ensemble.json\")) as json_file:\n",
    "    best_ensemble = json.load(json_file)\n",
    "print(\"----- BEST ENSEMBLE -----\")\n",
    "for field in [\"name\", \"models\", \"metrics\"]:\n",
    "  print(f\"{field}:\", best_ensemble.get(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ae0af9-e564-4167-853e-2d3ca2a8c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = {}\n",
    "for model in best_ensemble.get(\"models\"):  \n",
    "  with open(os.path.join(os.path.join(EXP_PATH, model), \"model-evaluation.json\")) as json_file:\n",
    "      model_evaluation[model] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f193bad-8f3f-481b-a60a-2c6b15fcb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def vote(predictions, weighted=False, weights=None):\n",
    "  votes = list()  \n",
    "  for i in range(len(labels)):    \n",
    "    curr_label_preds = [preds[i] for preds in predictions]    \n",
    "    voting = sum(curr_label_preds * weights) if weighted else sum(curr_label_preds)/len(curr_label_preds)\n",
    "    votes.append(0 if voting < 0.5 else 1)  \n",
    "  return votes\n",
    "test_predictions = list()\n",
    "def predict_ensemble(ensemble_name, dataset_name, dataset, weighted=False):  \n",
    " for i in range(len(dataset.index)):\n",
    "    predictions = list()\n",
    "    ensemble_models = best_ensemble.get(\"models\")    \n",
    "    for model_name in ensemble_models:\n",
    "      curr_model_outputs = model_evaluation[model_name].get(f\"{dataset_name}_model_outputs\")\n",
    "      predictions.append(curr_model_outputs[i])\n",
    "    weights = list()    \n",
    "    if weighted:      \n",
    "      f1_scores_list = [model_evaluation[model_name][\"metrics\"].get(\"weighted_f1\")                        \n",
    "                        for model_name in best_ensemble.get(\"models\")]\n",
    "      weights = normalize([f1_scores_list], norm=\"l1\")[0]\n",
    "    ensemble_pred = vote(predictions, weighted, weights)\n",
    "    test_predictions.append(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae2c70b-e73a-4524-8a3b-e2eaecee3c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.32s/it]                                                                                                                                                                                                                  \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 186/186 [01:59<00:00,  1.55it/s]\n",
      "3it [00:03,  1.13s/it]                                                                                                                                                                                                                  \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 186/186 [01:58<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions: [[0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for model_name in best_ensemble.get(\"models\"):\n",
    "  model_predictions, model_raw_outputs = models.get(model_name).predict(test[\"text\"].tolist())\n",
    "  model_evaluation[model_name][\"test_model_outputs\"] = model_raw_outputs\n",
    "  model_evaluation[model_name][\"test_predictions\"] = model_predictions\n",
    "predict_ensemble(best_ensemble.get(\"name\"), \"test\", test, weighted=WEIGHTED)\n",
    "n = 5\n",
    "print(f\"First {n} predictions:\", test_predictions[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be40601-eb87-4af1-b983-a2dc50119151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>political</th>\n",
       "      <th>racial/ethnic</th>\n",
       "      <th>religious</th>\n",
       "      <th>gender/sexual</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_1927fe24b83567b6383c90c35473cc32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_73b413c77432d415f2b63397ccbcda28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_5f0a632b6b0b4544b5fed6c84bd1b997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b23cc0db2a4e552a93fbbfe4e4d2f45f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_90240d10f79a2761cbea0b76e1553a6f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa_bfb5305232c58a214ace4bf4b74a0d08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spa_5734f86d92c6fbd89d4c2dae640bdf1f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa_b16cfe3434da104f2f19105191b8ffbb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spa_c1ea290e5e71ec4a3666563cc62cf410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spa_d086bcb58ad688925bc703c8602e4117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  political  racial/ethnic  religious  \\\n",
       "0  spa_1927fe24b83567b6383c90c35473cc32          0              0          0   \n",
       "1  spa_73b413c77432d415f2b63397ccbcda28          0              0          0   \n",
       "2  spa_5f0a632b6b0b4544b5fed6c84bd1b997          0              0          0   \n",
       "3  spa_b23cc0db2a4e552a93fbbfe4e4d2f45f          0              0          0   \n",
       "4  spa_90240d10f79a2761cbea0b76e1553a6f          0              0          0   \n",
       "5  spa_bfb5305232c58a214ace4bf4b74a0d08          0              0          0   \n",
       "6  spa_5734f86d92c6fbd89d4c2dae640bdf1f          1              0          0   \n",
       "7  spa_b16cfe3434da104f2f19105191b8ffbb          0              0          0   \n",
       "8  spa_c1ea290e5e71ec4a3666563cc62cf410          0              0          0   \n",
       "9  spa_d086bcb58ad688925bc703c8602e4117          0              0          0   \n",
       "\n",
       "   gender/sexual  other  \n",
       "0              0      1  \n",
       "1              0      0  \n",
       "2              0      0  \n",
       "3              0      0  \n",
       "4              0      0  \n",
       "5              0      0  \n",
       "6              0      1  \n",
       "7              0      0  \n",
       "8              0      0  \n",
       "9              0      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = test[[\"id\"]].rename(columns={\"id\": \"id\"})\n",
    "for i in range(len(labels)):\n",
    "  test_output[labels[i]] = [pred[i] for pred in test_predictions]\n",
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdb4fdc6-7c94-4a11-a51a-7ea34571cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(os.path.join(OUTPUT, \"results_test3.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd3f09-85aa-4e46-88ed-7d62f737571a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
