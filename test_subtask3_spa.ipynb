{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a48db3-cf2e-4578-ab7d-770544449535",
   "metadata": {},
   "source": [
    "# dev_phase测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a51b29-b508-464e-a22a-4f7ba68e3481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 10 20:58:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8             28W /  350W |   23807MiB /  24576MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3920    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            4748    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           10108    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10168    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10852    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           11176    C+G   ...8wekyb3d8bbwe\\WebViewHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11696    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13932    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13940    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           14740    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15616    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15900    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19412    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           20576    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           23320    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           25524    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           32620    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           33952      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           36852    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           37668      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           41648    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           44168      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           44176    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           45580    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           46796    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           46816    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           47280    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47356    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           50772    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           51868    C+G   ...0.2.1\\jbr\\bin\\jcef_helper.exe      N/A      |\n",
      "|    0   N/A  N/A           52948    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           53208      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           54424    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           58344    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59364    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59536      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           63456    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           64552    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           64820    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           66724      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           70912    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           71576      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           72048    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           72312    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           73192      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           77448    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           77860    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           79908    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc308baa-8cf7-46b6-ba20-8307c320a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "WEIGHTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00c8015c-0887-46ac-9e0f-3ceabc63c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(load_dataset(\"dev_phase/subtask3/dev/spa\", split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8da96b4-e1d9-4fa6-a8ef-847ccde8cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split size: 165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>\"puta weon, los progres arruinaron el indio pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>#mexico | el gobierno informo que esta dialoga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>a abortar el mojon que traen atorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>a comerrrrr\\n(la salsa es curry indio)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>aborto libre y retroactivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065   \n",
       "\n",
       "                                                text  \n",
       "0  \"puta weon, los progres arruinaron el indio pi...  \n",
       "1  #mexico | el gobierno informo que esta dialoga...  \n",
       "2               a abortar el mojon que traen atorado  \n",
       "3             a comerrrrr\\n(la salsa es curry indio)  \n",
       "4                         aborto libre y retroactivo  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"stereotype\", \"vilification\", \"dehumanization\", \"extreme_language\", \"lack_of_empathy\", \"invalidation\"]\n",
    "def get_text_and_label(df):  \n",
    "  return df.rename(columns={\"text\": \"text\"})[[\"id\", \"text\"]]\n",
    "test = get_text_and_label(test)\n",
    "print(\"Test split size:\", len(test.index))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5de4b28-8ee2-4401-a2e8-d8066d5e91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = \"lr-2e-05-optimizer-AdamW-epochs-10-RMSEduringTraining\"\n",
    "EXP = \"10-11-2025-01-36\"\n",
    "# TRANSFORMERS = \"top_transformers\"  \n",
    "TRANSFORMERS = \"10-11-2025-01-36\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54cdabce-fa36-4cb2-ae97-4218c2e39236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: ./outputs/10-11-2025-01-36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./outputs/\"\n",
    "EXP_PATH = os.path.join(PATH, EXP)\n",
    "TRANSFORMERS_PATH = os.path.join(PATH, TRANSFORMERS)\n",
    "print(\"Current working dir:\", EXP_PATH)\n",
    "OUTPUT = os.path.join(EXP_PATH, \"test\")\n",
    "# 第一次使用时创建文件夹\n",
    "# os.mkdir(EXP_PATH)\n",
    "# os.mkdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c485887e-a838-46d0-8dc5-80ea0c47444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {    \n",
    "\"mbert-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-cased\"    \n",
    "},    \n",
    "\"mbert-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-uncased\"    \n",
    "},    \n",
    "\"roberta\": {        \n",
    "\"model_type\": \"roberta\",        \n",
    "\"model_name\": \"models--FacebookAI--roberta-base\"    \n",
    "},    \n",
    "\"beto-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-cased\"    \n",
    "},    \n",
    "\"beto-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-uncased\"    \n",
    "},    \n",
    "\"distilbert-multi\": {        \n",
    "\"model_type\": \"distilbert\",        \n",
    "\"model_name\": \"models--distilbert--distilbert-base-multilingual-cased\"    \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e6dff70-fca9-4021-8c8b-b97ab17c99bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mbert-cased\n",
      "model: mbert-uncased\n",
      "model: roberta\n",
      "model: beto-cased\n",
      "model: beto-uncased\n",
      "model: distilbert-multi\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "for model, fields in models.items():    \n",
    "  print(\"model:\",model)\n",
    "  models[model] = MultiLabelClassificationModel(fields[\"model_type\"], os.path.join(TRANSFORMERS_PATH, model), use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ff1feef-2a7e-4e05-a639-b6bc0a76ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BEST ENSEMBLE -----\n",
      "name: ensemble18\n",
      "models: ['beto-cased', 'beto-uncased']\n",
      "metrics: {'accuracy': 0.90469, 'macro_f1': 0.9484, 'macro_precision': 0.95785, 'macro_recall': 0.94031, 'weighted_f1': 0.95304}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_ensemble = {}\n",
    "with open(os.path.join(EXP_PATH, \"best-ensemble.json\")) as json_file:\n",
    "    best_ensemble = json.load(json_file)\n",
    "print(\"----- BEST ENSEMBLE -----\")\n",
    "for field in [\"name\", \"models\", \"metrics\"]:\n",
    "  print(f\"{field}:\", best_ensemble.get(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b818f009-115d-40b8-bd22-eadbdecae834",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = {}\n",
    "for model in best_ensemble.get(\"models\"):  \n",
    "  with open(os.path.join(os.path.join(EXP_PATH, model), \"model-evaluation.json\"), encoding=\"utf-8\") as json_file:\n",
    "      model_evaluation[model] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0fd6fc6-371e-4ba6-883f-36dad4a5b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def vote(predictions, weighted=False, weights=None):\n",
    "  votes = list()  \n",
    "  for i in range(len(labels)):    \n",
    "    curr_label_preds = [preds[i] for preds in predictions]    \n",
    "    voting = sum(curr_label_preds * weights) if weighted else sum(curr_label_preds)/len(curr_label_preds)\n",
    "    votes.append(0 if voting < 0.5 else 1)  \n",
    "  return votes\n",
    "test_predictions = list()\n",
    "def predict_ensemble(ensemble_name, dataset_name, dataset, weighted=False):  \n",
    " for i in range(len(dataset.index)):\n",
    "    predictions = list()\n",
    "    ensemble_models = best_ensemble.get(\"models\")    \n",
    "    for model_name in ensemble_models:\n",
    "      curr_model_outputs = model_evaluation[model_name].get(f\"{dataset_name}_model_outputs\")\n",
    "      predictions.append(curr_model_outputs[i])\n",
    "    weights = list()    \n",
    "    if weighted:      \n",
    "      f1_scores_list = [model_evaluation[model_name][\"metrics\"].get(\"weighted_f1\")                        \n",
    "                        for model_name in best_ensemble.get(\"models\")]\n",
    "      weights = normalize([f1_scores_list], norm=\"l1\")[0]\n",
    "    ensemble_pred = vote(predictions, weighted, weights)\n",
    "    test_predictions.append(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5aeddf3-55af-45bd-800e-d4fe46a7c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.50s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:13<00:00,  1.57it/s]\n",
      "1it [00:02,  2.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:13<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions: [[0, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in best_ensemble.get(\"models\"):\n",
    "  model_predictions, model_raw_outputs = models.get(model_name).predict(test[\"text\"].tolist())\n",
    "  model_evaluation[model_name][\"test_model_outputs\"] = model_raw_outputs\n",
    "  model_evaluation[model_name][\"test_predictions\"] = model_predictions\n",
    "predict_ensemble(best_ensemble.get(\"name\"), \"test\", test, weighted=WEIGHTED)\n",
    "n = 5\n",
    "print(f\"First {n} predictions:\", test_predictions[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d85898c4-49a7-4a19-9fe0-62b6db342e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>vilification</th>\n",
       "      <th>dehumanization</th>\n",
       "      <th>extreme_language</th>\n",
       "      <th>lack_of_empathy</th>\n",
       "      <th>invalidation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa_ae37ea460c69447a6e03c3dedf946126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spa_dda5476589aee9d32a5ee7432805999c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa_1a721702be59d86b876810539ad9cf66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spa_bec4c459366c1a56819a55c01dc1a77d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  stereotype  vilification  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888           0             1   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc           0             0   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe           0             0   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928           0             0   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065           0             0   \n",
       "5  spa_ae37ea460c69447a6e03c3dedf946126           0             0   \n",
       "6  spa_dda5476589aee9d32a5ee7432805999c           0             1   \n",
       "7  spa_1a721702be59d86b876810539ad9cf66           0             0   \n",
       "8  spa_bec4c459366c1a56819a55c01dc1a77d           0             0   \n",
       "9  spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9           1             1   \n",
       "\n",
       "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
       "0               0                 1                0             0  \n",
       "1               0                 0                0             0  \n",
       "2               0                 0                0             0  \n",
       "3               0                 0                0             0  \n",
       "4               0                 0                0             0  \n",
       "5               0                 0                0             0  \n",
       "6               0                 0                0             1  \n",
       "7               0                 0                0             0  \n",
       "8               0                 0                0             0  \n",
       "9               0                 0                1             1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = test[[\"id\"]].rename(columns={\"id\": \"id\"})\n",
    "for i in range(len(labels)):\n",
    "  test_output[labels[i]] = [pred[i] for pred in test_predictions]\n",
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14859ef4-50f1-4604-94c8-a5893d30b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(os.path.join(OUTPUT, \"results_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b2113-b8ce-48bb-b449-4bf262a793f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2476151-6903-4403-b982-7079b7843ad6",
   "metadata": {},
   "source": [
    "# dev_phase2测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5991e4dc-c68e-48af-8187-974efaa6812c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 10 21:00:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8             27W /  350W |   23808MiB /  24576MiB |      8%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3920    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            4748    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           10108    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10168    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10852    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           11176    C+G   ...8wekyb3d8bbwe\\WebViewHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11696    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13932    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13940    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           14740    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15616    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15900    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19412    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           20576    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           23320    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           25524    C+G   ....0.3537.99\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           32620    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           33952      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           36852    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           37668      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           41648    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           44168      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           44176    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           45580    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           46796    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           46816    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           47280    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47356    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           50772    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           51868    C+G   ...0.2.1\\jbr\\bin\\jcef_helper.exe      N/A      |\n",
      "|    0   N/A  N/A           52948    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           53208      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           54424    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           58344    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59364    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           59536      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           63456    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           64552    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           64820    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           66724      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           70912    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           71576      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           72048    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           72312    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           73192      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           77448    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           77860    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           79908    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd89192e-ab6f-46d9-bfbf-36852319c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "WEIGHTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f890a804-7826-4c27-90d4-506f13aa848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(load_dataset(\"dev_phase2/subtask3/dev/spa\", split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f80ccc0b-99cf-4619-a190-171267ab55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split size: 165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>\"puta weon, los progres arruinaron el indio pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>#mexico | el gobierno informo que esta dialoga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>a abortar el mojon que traen atorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>a comerrrrr\\n(la salsa es curry indio)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>aborto libre y retroactivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065   \n",
       "\n",
       "                                                text  \n",
       "0  \"puta weon, los progres arruinaron el indio pi...  \n",
       "1  #mexico | el gobierno informo que esta dialoga...  \n",
       "2               a abortar el mojon que traen atorado  \n",
       "3             a comerrrrr\\n(la salsa es curry indio)  \n",
       "4                         aborto libre y retroactivo  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"stereotype\", \"vilification\", \"dehumanization\", \"extreme_language\", \"lack_of_empathy\", \"invalidation\"]\n",
    "def get_text_and_label(df):  \n",
    "  return df.rename(columns={\"text\": \"text\"})[[\"id\", \"text\"]]\n",
    "test = get_text_and_label(test)\n",
    "print(\"Test split size:\", len(test.index))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e12c1c4e-f152-4dee-b361-737a31da1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = \"lr-2e-05-optimizer-AdamW-epochs-10-RMSEduringTraining\"\n",
    "EXP = \"10-11-2025-01-36\"\n",
    "# TRANSFORMERS = \"top_transformers\"  \n",
    "TRANSFORMERS = \"10-11-2025-01-36\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e05a76a-8e88-4554-bc82-e794d6273395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: ./outputs/10-11-2025-01-36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./outputs/\"\n",
    "EXP_PATH = os.path.join(PATH, EXP)\n",
    "TRANSFORMERS_PATH = os.path.join(PATH, TRANSFORMERS)\n",
    "print(\"Current working dir:\", EXP_PATH)\n",
    "OUTPUT = os.path.join(EXP_PATH, \"test\")\n",
    "# 第一次使用时创建文件夹\n",
    "# os.mkdir(EXP_PATH)\n",
    "# os.mkdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "794f344d-9e70-49f8-89a0-60b46eabbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {    \n",
    "\"mbert-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-cased\"    \n",
    "},    \n",
    "\"mbert-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-uncased\"    \n",
    "},    \n",
    "\"roberta\": {        \n",
    "\"model_type\": \"roberta\",        \n",
    "\"model_name\": \"models--FacebookAI--roberta-base\"    \n",
    "},    \n",
    "\"beto-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-cased\"    \n",
    "},    \n",
    "\"beto-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-uncased\"    \n",
    "},    \n",
    "\"distilbert-multi\": {        \n",
    "\"model_type\": \"distilbert\",        \n",
    "\"model_name\": \"models--distilbert--distilbert-base-multilingual-cased\"    \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88eda4ba-f717-47ab-989c-d54b1d19de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mbert-cased\n",
      "model: mbert-uncased\n",
      "model: roberta\n",
      "model: beto-cased\n",
      "model: beto-uncased\n",
      "model: distilbert-multi\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "for model, fields in models.items():    \n",
    "  print(\"model:\",model)\n",
    "  models[model] = MultiLabelClassificationModel(fields[\"model_type\"], os.path.join(TRANSFORMERS_PATH, model), use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1eb666c6-ed9a-405d-8ba0-05a8640c4039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BEST ENSEMBLE -----\n",
      "name: ensemble18\n",
      "models: ['beto-cased', 'beto-uncased']\n",
      "metrics: {'accuracy': 0.90469, 'macro_f1': 0.9484, 'macro_precision': 0.95785, 'macro_recall': 0.94031, 'weighted_f1': 0.95304}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_ensemble = {}\n",
    "with open(os.path.join(EXP_PATH, \"best-ensemble.json\")) as json_file:\n",
    "    best_ensemble = json.load(json_file)\n",
    "print(\"----- BEST ENSEMBLE -----\")\n",
    "for field in [\"name\", \"models\", \"metrics\"]:\n",
    "  print(f\"{field}:\", best_ensemble.get(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11b2a24a-02a6-40d9-aa2a-25a88ea52a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = {}\n",
    "for model in best_ensemble.get(\"models\"):  \n",
    "  with open(os.path.join(os.path.join(EXP_PATH, model), \"model-evaluation.json\"), encoding=\"utf-8\") as json_file:\n",
    "      model_evaluation[model] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db5a56e0-ccae-4550-b0e6-8cab285bd027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def vote(predictions, weighted=False, weights=None):\n",
    "  votes = list()  \n",
    "  for i in range(len(labels)):    \n",
    "    curr_label_preds = [preds[i] for preds in predictions]    \n",
    "    voting = sum(curr_label_preds * weights) if weighted else sum(curr_label_preds)/len(curr_label_preds)\n",
    "    votes.append(0 if voting < 0.5 else 1)  \n",
    "  return votes\n",
    "test_predictions = list()\n",
    "def predict_ensemble(ensemble_name, dataset_name, dataset, weighted=False):  \n",
    " for i in range(len(dataset.index)):\n",
    "    predictions = list()\n",
    "    ensemble_models = best_ensemble.get(\"models\")    \n",
    "    for model_name in ensemble_models:\n",
    "      curr_model_outputs = model_evaluation[model_name].get(f\"{dataset_name}_model_outputs\")\n",
    "      predictions.append(curr_model_outputs[i])\n",
    "    weights = list()    \n",
    "    if weighted:      \n",
    "      f1_scores_list = [model_evaluation[model_name][\"metrics\"].get(\"weighted_f1\")                        \n",
    "                        for model_name in best_ensemble.get(\"models\")]\n",
    "      weights = normalize([f1_scores_list], norm=\"l1\")[0]\n",
    "    ensemble_pred = vote(predictions, weighted, weights)\n",
    "    test_predictions.append(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64bec216-cb56-4d1e-8211-917fc30cb4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.40s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:12<00:00,  1.64it/s]\n",
      "1it [00:02,  2.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:12<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions: [[0, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in best_ensemble.get(\"models\"):\n",
    "  model_predictions, model_raw_outputs = models.get(model_name).predict(test[\"text\"].tolist())\n",
    "  model_evaluation[model_name][\"test_model_outputs\"] = model_raw_outputs\n",
    "  model_evaluation[model_name][\"test_predictions\"] = model_predictions\n",
    "predict_ensemble(best_ensemble.get(\"name\"), \"test\", test, weighted=WEIGHTED)\n",
    "n = 5\n",
    "print(f\"First {n} predictions:\", test_predictions[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8d8ef10-1747-46fc-b848-3618070f269b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>vilification</th>\n",
       "      <th>dehumanization</th>\n",
       "      <th>extreme_language</th>\n",
       "      <th>lack_of_empathy</th>\n",
       "      <th>invalidation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_330f5a37bfec2146ef834b8c3a505888</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_09443002d51a05f05c08bde37cb786bc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_6344425e0525930c1bbf6b37ba0b5ebe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b6aa7a3bead18c0b34622e88aabd5928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_e25a2f619a1dd1c504d5bc44db426065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa_ae37ea460c69447a6e03c3dedf946126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spa_dda5476589aee9d32a5ee7432805999c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa_1a721702be59d86b876810539ad9cf66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spa_bec4c459366c1a56819a55c01dc1a77d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  stereotype  vilification  \\\n",
       "0  spa_330f5a37bfec2146ef834b8c3a505888           0             1   \n",
       "1  spa_09443002d51a05f05c08bde37cb786bc           0             0   \n",
       "2  spa_6344425e0525930c1bbf6b37ba0b5ebe           0             0   \n",
       "3  spa_b6aa7a3bead18c0b34622e88aabd5928           0             0   \n",
       "4  spa_e25a2f619a1dd1c504d5bc44db426065           0             0   \n",
       "5  spa_ae37ea460c69447a6e03c3dedf946126           0             0   \n",
       "6  spa_dda5476589aee9d32a5ee7432805999c           0             1   \n",
       "7  spa_1a721702be59d86b876810539ad9cf66           0             0   \n",
       "8  spa_bec4c459366c1a56819a55c01dc1a77d           0             0   \n",
       "9  spa_0a38d1ef4f1ea18eaa9a6d6f5bbfe4b9           1             1   \n",
       "\n",
       "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
       "0               0                 1                0             0  \n",
       "1               0                 0                0             0  \n",
       "2               0                 0                0             0  \n",
       "3               0                 0                0             0  \n",
       "4               0                 0                0             0  \n",
       "5               0                 0                0             0  \n",
       "6               0                 0                0             1  \n",
       "7               0                 0                0             0  \n",
       "8               0                 0                0             0  \n",
       "9               0                 0                1             1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = test[[\"id\"]].rename(columns={\"id\": \"id\"})\n",
    "for i in range(len(labels)):\n",
    "  test_output[labels[i]] = [pred[i] for pred in test_predictions]\n",
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "347bfd63-5789-453f-af54-98733afee8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(os.path.join(OUTPUT, \"results_test2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433a843-6ec1-469c-a09f-dca75cf7083d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de432061-5b91-4866-9114-1a803095960a",
   "metadata": {},
   "source": [
    "# test_phase测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4f0fa1-0625-4b0a-89b0-56f7555fbc71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  1 13:43:29 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.40                 Driver Version: 576.40         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   49C    P8             29W /  390W |   23710MiB /  24576MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2288    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            3044    C+G   ....0.3719.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            3124    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            4548    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7088    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7376    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7760      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A            7972    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A            8308    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            8784    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8996    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           11708    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11716    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12776    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13752    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           16792    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16932    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18292    C+G   ....0.3719.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19284      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           20816    C+G   ...0.2.1\\jbr\\bin\\jcef_helper.exe      N/A      |\n",
      "|    0   N/A  N/A           24332    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           24492    C+G   ....0.3719.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24744      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           25024    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           25504    C+G   ...8wekyb3d8bbwe\\M365Copilot.exe      N/A      |\n",
      "|    0   N/A  N/A           26696      C   ...SemEval2025_Task11\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458ecf70-ee9f-45fe-8ef7-8dffb55d618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "WEIGHTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0a5e68-daa4-4f60-ac5d-61ccd3c1afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\SemEval2025_Task11\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(load_dataset(\"test_phase/subtask3/test/spa\", split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20266fde-b011-43cf-bbc6-072eb4cec4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split size: 1488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_1927fe24b83567b6383c90c35473cc32</td>\n",
       "      <td>\"penas severas para el aborto porque yo estuve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_73b413c77432d415f2b63397ccbcda28</td>\n",
       "      <td>\"si eres pobre debes abortar\" eso lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_5f0a632b6b0b4544b5fed6c84bd1b997</td>\n",
       "      <td>#brasil exige a #eeuu \"respeto\" para repatriad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b23cc0db2a4e552a93fbbfe4e4d2f45f</td>\n",
       "      <td>#honduras | el canciller anuncio la llegada de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_90240d10f79a2761cbea0b76e1553a6f</td>\n",
       "      <td>#internacionales | el presidente de colombia, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  spa_1927fe24b83567b6383c90c35473cc32   \n",
       "1  spa_73b413c77432d415f2b63397ccbcda28   \n",
       "2  spa_5f0a632b6b0b4544b5fed6c84bd1b997   \n",
       "3  spa_b23cc0db2a4e552a93fbbfe4e4d2f45f   \n",
       "4  spa_90240d10f79a2761cbea0b76e1553a6f   \n",
       "\n",
       "                                                text  \n",
       "0  \"penas severas para el aborto porque yo estuve...  \n",
       "1              \"si eres pobre debes abortar\" eso lei  \n",
       "2  #brasil exige a #eeuu \"respeto\" para repatriad...  \n",
       "3  #honduras | el canciller anuncio la llegada de...  \n",
       "4  #internacionales | el presidente de colombia, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"stereotype\", \"vilification\", \"dehumanization\", \"extreme_language\", \"lack_of_empathy\", \"invalidation\"]\n",
    "def get_text_and_label(df):  \n",
    "  return df.rename(columns={\"text\": \"text\"})[[\"id\", \"text\"]]\n",
    "test = get_text_and_label(test)\n",
    "print(\"Test split size:\", len(test.index))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b2853b-7fa4-47bc-a604-746b950a962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = \"lr-2e-05-optimizer-AdamW-epochs-10-RMSEduringTraining\"\n",
    "EXP = \"10-11-2025-01-36\"\n",
    "# TRANSFORMERS = \"top_transformers\"  \n",
    "TRANSFORMERS = \"10-11-2025-01-36\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d0058e-5410-4b68-bc4a-8b7efa92cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: ./outputs/10-11-2025-01-36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = \"./outputs/\"\n",
    "EXP_PATH = os.path.join(PATH, EXP)\n",
    "TRANSFORMERS_PATH = os.path.join(PATH, TRANSFORMERS)\n",
    "print(\"Current working dir:\", EXP_PATH)\n",
    "OUTPUT = os.path.join(EXP_PATH, \"test\")\n",
    "# 第一次使用时创建文件夹\n",
    "# os.mkdir(EXP_PATH)\n",
    "# os.mkdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e2938e-5233-4c06-aa3c-71390e8344d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {    \n",
    "\"mbert-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-cased\"    \n",
    "},    \n",
    "\"mbert-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--google-bert--bert-base-multilingual-uncased\"    \n",
    "},    \n",
    "\"roberta\": {        \n",
    "\"model_type\": \"roberta\",        \n",
    "\"model_name\": \"models--FacebookAI--roberta-base\"    \n",
    "},    \n",
    "\"beto-cased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-cased\"    \n",
    "},    \n",
    "\"beto-uncased\": {        \n",
    "\"model_type\": \"bert\",        \n",
    "\"model_name\": \"models--dccuchile--bert-base-spanish-wwm-uncased\"    \n",
    "},    \n",
    "\"distilbert-multi\": {        \n",
    "\"model_type\": \"distilbert\",        \n",
    "\"model_name\": \"models--distilbert--distilbert-base-multilingual-cased\"    \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ca7fac-cbdf-46df-97b5-9bb53fed5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: mbert-cased\n",
      "model: mbert-uncased\n",
      "model: roberta\n",
      "model: beto-cased\n",
      "model: beto-uncased\n",
      "model: distilbert-multi\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "for model, fields in models.items():    \n",
    "  print(\"model:\",model)\n",
    "  models[model] = MultiLabelClassificationModel(fields[\"model_type\"], os.path.join(TRANSFORMERS_PATH, model), use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832e84fb-23f7-4c11-8a96-b57d5632c599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BEST ENSEMBLE -----\n",
      "name: ensemble18\n",
      "models: ['beto-cased', 'beto-uncased']\n",
      "metrics: {'accuracy': 0.90469, 'macro_f1': 0.9484, 'macro_precision': 0.95785, 'macro_recall': 0.94031, 'weighted_f1': 0.95304}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_ensemble = {}\n",
    "with open(os.path.join(EXP_PATH, \"best-ensemble.json\")) as json_file:\n",
    "    best_ensemble = json.load(json_file)\n",
    "print(\"----- BEST ENSEMBLE -----\")\n",
    "for field in [\"name\", \"models\", \"metrics\"]:\n",
    "  print(f\"{field}:\", best_ensemble.get(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e686be5-3bc1-4ada-be64-cb3ece39e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = {}\n",
    "for model in best_ensemble.get(\"models\"):  \n",
    "  with open(os.path.join(os.path.join(EXP_PATH, model), \"model-evaluation.json\"), encoding=\"utf-8\") as json_file:\n",
    "      model_evaluation[model] = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e9deb70-bc97-4939-8254-582eb9cf66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "def vote(predictions, weighted=False, weights=None):\n",
    "  votes = list()  \n",
    "  for i in range(len(labels)):    \n",
    "    curr_label_preds = [preds[i] for preds in predictions]    \n",
    "    voting = sum(curr_label_preds * weights) if weighted else sum(curr_label_preds)/len(curr_label_preds)\n",
    "    votes.append(0 if voting < 0.5 else 1)  \n",
    "  return votes\n",
    "test_predictions = list()\n",
    "def predict_ensemble(ensemble_name, dataset_name, dataset, weighted=False):  \n",
    " for i in range(len(dataset.index)):\n",
    "    predictions = list()\n",
    "    ensemble_models = best_ensemble.get(\"models\")    \n",
    "    for model_name in ensemble_models:\n",
    "      curr_model_outputs = model_evaluation[model_name].get(f\"{dataset_name}_model_outputs\")\n",
    "      predictions.append(curr_model_outputs[i])\n",
    "    weights = list()    \n",
    "    if weighted:      \n",
    "      f1_scores_list = [model_evaluation[model_name][\"metrics\"].get(\"weighted_f1\")                        \n",
    "                        for model_name in best_ensemble.get(\"models\")]\n",
    "      weights = normalize([f1_scores_list], norm=\"l1\")[0]\n",
    "    ensemble_pred = vote(predictions, weighted, weights)\n",
    "    test_predictions.append(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5164bfe-52de-43d8-bf37-efca891e90a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.28s/it]                                                                                                                                                                                                                  \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 186/186 [02:00<00:00,  1.55it/s]\n",
      "3it [00:03,  1.11s/it]                                                                                                                                                                                                                  \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 186/186 [01:58<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions: [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for model_name in best_ensemble.get(\"models\"):\n",
    "  model_predictions, model_raw_outputs = models.get(model_name).predict(test[\"text\"].tolist())\n",
    "  model_evaluation[model_name][\"test_model_outputs\"] = model_raw_outputs\n",
    "  model_evaluation[model_name][\"test_predictions\"] = model_predictions\n",
    "predict_ensemble(best_ensemble.get(\"name\"), \"test\", test, weighted=WEIGHTED)\n",
    "n = 5\n",
    "print(f\"First {n} predictions:\", test_predictions[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd12969c-8f64-4e27-b6a7-f0409ec4370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>vilification</th>\n",
       "      <th>dehumanization</th>\n",
       "      <th>extreme_language</th>\n",
       "      <th>lack_of_empathy</th>\n",
       "      <th>invalidation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa_1927fe24b83567b6383c90c35473cc32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa_73b413c77432d415f2b63397ccbcda28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spa_5f0a632b6b0b4544b5fed6c84bd1b997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spa_b23cc0db2a4e552a93fbbfe4e4d2f45f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spa_90240d10f79a2761cbea0b76e1553a6f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spa_bfb5305232c58a214ace4bf4b74a0d08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spa_5734f86d92c6fbd89d4c2dae640bdf1f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spa_b16cfe3434da104f2f19105191b8ffbb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spa_c1ea290e5e71ec4a3666563cc62cf410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spa_d086bcb58ad688925bc703c8602e4117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  stereotype  vilification  \\\n",
       "0  spa_1927fe24b83567b6383c90c35473cc32           0             0   \n",
       "1  spa_73b413c77432d415f2b63397ccbcda28           0             0   \n",
       "2  spa_5f0a632b6b0b4544b5fed6c84bd1b997           0             0   \n",
       "3  spa_b23cc0db2a4e552a93fbbfe4e4d2f45f           0             0   \n",
       "4  spa_90240d10f79a2761cbea0b76e1553a6f           0             0   \n",
       "5  spa_bfb5305232c58a214ace4bf4b74a0d08           0             0   \n",
       "6  spa_5734f86d92c6fbd89d4c2dae640bdf1f           1             1   \n",
       "7  spa_b16cfe3434da104f2f19105191b8ffbb           0             0   \n",
       "8  spa_c1ea290e5e71ec4a3666563cc62cf410           0             0   \n",
       "9  spa_d086bcb58ad688925bc703c8602e4117           0             0   \n",
       "\n",
       "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
       "0               0                 0                0             0  \n",
       "1               0                 0                1             0  \n",
       "2               0                 0                0             0  \n",
       "3               0                 0                0             0  \n",
       "4               0                 0                0             0  \n",
       "5               0                 0                0             0  \n",
       "6               0                 0                0             1  \n",
       "7               0                 0                0             0  \n",
       "8               0                 0                0             0  \n",
       "9               0                 0                0             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = test[[\"id\"]].rename(columns={\"id\": \"id\"})\n",
    "for i in range(len(labels)):\n",
    "  test_output[labels[i]] = [pred[i] for pred in test_predictions]\n",
    "test_output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c5f446-c9f6-4134-8d28-b600dccb4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(os.path.join(OUTPUT, \"results_test3.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db0214-fe8b-489a-afda-4ac7d8fa17f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
